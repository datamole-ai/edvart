{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2481a89",
   "metadata": {},
   "source": [
    "# [INSERT DATASET NAME] Report\n",
    "[INSERT DATASET DESCRIPTION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d08f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.graphics import tsaplots\n",
    "\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode()\n",
    "\n",
    "import edvart\n",
    "from edvart import utils\n",
    "from edvart.data_types import is_numeric\n",
    "from edvart.pandas_formatting import dict_to_html, render_dictionary, series_to_frame, format_number, add_html_heading, subcells_html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0f01f",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b66d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = edvart.example_datasets.dataset_titanic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1628a74e",
   "metadata": {},
   "source": [
    "# Report Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4bb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Default list of names of columns which will be analyzed\n",
    "\"\"\"\n",
    "DEFAULT_COLUMN_SUBSET = dataset.columns\n",
    "\n",
    "\"\"\"\n",
    "Default dictionary of descriptive statistics that will be calculated for numerical columns\n",
    "    Dicionary signature: 'StatisticName': stat_func\n",
    "    stat_func signature: stat_func(series: pandas.Series) -> Any\n",
    "\"\"\"\n",
    "DEFAULT_DESCRIPTIVE_STATISTICS = {\n",
    "    'Number of unique values': utils.num_unique_values,\n",
    "    'Sum': utils.sum_,\n",
    "    'Mean': utils.mean,\n",
    "    'Mode': utils.mode,\n",
    "    'Standard deviation': utils.std,\n",
    "    'Mean absolute deviation': utils.mad,\n",
    "    'Median absolute deviation': utils.median_absolute_deviation,\n",
    "    'Coefficient of variation': utils.coefficient_of_variation,\n",
    "    'Kurtosis': utils.kurtosis,\n",
    "    'Skewness': utils.skewness\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "Default dictionary of quantile statistics that will be calculated for numerical columns\n",
    "    Dicionary signature: 'StatisticName': stat_func\n",
    "    stat_func signature: stat_func(series: pandas.Series) -> Any\n",
    "\"\"\"\n",
    "DEFAULT_QUANTILE_STATISTICS = {\n",
    "    'Minimum': utils.minimum,\n",
    "    'Maximum': utils.maximum,\n",
    "    'Q1': utils.quartile1,\n",
    "    'Median': utils.median,\n",
    "    'Q3': utils.quartile3,\n",
    "    'Range': utils.value_range,\n",
    "    'IQR': utils.iqr,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7bd3f7",
   "metadata": {},
   "source": [
    "# Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafca02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info calculation\n",
    "missing_cells = dataset.isna().sum().sum()\n",
    "missing_cells_percent = 100 * missing_cells / (dataset.shape[0] * dataset.shape[1])\n",
    "\n",
    "zeros = (dataset == 0).sum().sum()\n",
    "zeros_percent = 100 * zeros / (dataset.shape[0] * dataset.shape[1])\n",
    "\n",
    "duplicate_rows = dataset.duplicated().sum()\n",
    "duplicate_rows_percent = 100 * duplicate_rows / len(dataset)\n",
    "\n",
    "dataset_info_rows = {\n",
    "    'Rows': dataset.shape[0],\n",
    "    'Columns': dataset.shape[1],\n",
    "    'Missing cells': f'{missing_cells} ({missing_cells_percent:,.02f} %)',\n",
    "    'Zeros': f'{zeros} ({zeros_percent:.02f} %)',\n",
    "    'Duplicate rows': f'{duplicate_rows} ({duplicate_rows_percent:,.02f} %)'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d36c33",
   "metadata": {},
   "source": [
    "## Quick Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render\n",
    "render_dictionary(dataset_info_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1267fc4",
   "metadata": {},
   "source": [
    "## Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62fb417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dtypes\n",
    "dtypes = dataset.dtypes\n",
    "dtypes_no_nans = (\n",
    "    dataset\n",
    "    .dropna(axis=1, how='all')\n",
    "    .dropna(axis=0)\n",
    "    .fillna(0, downcast='infer')\n",
    "    .dtypes\n",
    ")\n",
    "\n",
    "# Convert result to frame for viewing\n",
    "dtypes_frame = series_to_frame(\n",
    "    series=dtypes,\n",
    "    index_name='Column Name',\n",
    "    column_name='Data Type'\n",
    ")\n",
    "dtypes_no_nans_frame = series_to_frame(\n",
    "    series=dtypes_no_nans,\n",
    "    index_name='Column Name',\n",
    "    column_name='Data Type (after dropping NULL values)'\n",
    ")\n",
    "(\n",
    "    dtypes_frame\n",
    "    .merge(dtypes_no_nans_frame, on='Column Name', how='left')\n",
    "    .style\n",
    "    .hide(axis='index')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be2be3",
   "metadata": {},
   "source": [
    "## Dataset Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31559b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HEAD    = 5\n",
    "N_TAIL    = 5\n",
    "N_SAMPLES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9e4e64",
   "metadata": {},
   "source": [
    "### Dataset First Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b55c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(N_HEAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39eda98",
   "metadata": {},
   "source": [
    "### Dataset Last Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db353abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tail(N_TAIL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f80bfa0",
   "metadata": {},
   "source": [
    "### Dataset Random Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f822a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.sample(N_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10a8b0d",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Edit the COLUMN_SUBSET list to specify which columns will be considered in missing values counting\n",
    "\"\"\"\n",
    "\n",
    "COLUMN_SUBSET = DEFAULT_COLUMN_SUBSET\n",
    "\n",
    "if isinstance(COLUMN_SUBSET, str):\n",
    "    COLUMN_SUBSET = [COLUMN_SUBSET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efafd524",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATPLOTLIB_BAR_PLOT_ARGS = {\n",
    "    'figsize': (15, 6),\n",
    "    'title': 'Missing Values Percentage of Each Column',\n",
    "    'ylim': 0,\n",
    "    'legend': False,\n",
    "    'color': '#FFA07A'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388127a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null values\n",
    "null_count = dataset[COLUMN_SUBSET].isna().sum()\n",
    "null_percentage = 100 * null_count / len(dataset)\n",
    "\n",
    "# Convert series to frames\n",
    "null_count_frame = series_to_frame(\n",
    "    series=null_count,\n",
    "    index_name='Column Name',\n",
    "    column_name='Null Count'\n",
    ")\n",
    "null_percentage_frame = series_to_frame(\n",
    "    series=null_percentage,\n",
    "    index_name='Column Name',\n",
    "    column_name='Null %'\n",
    ")\n",
    "# Merge null count and percentage into one frame\n",
    "null_stats_frame = (\n",
    "    null_count_frame\n",
    "    .merge(null_percentage_frame, on='Column Name')\n",
    "    .sort_values('Null Count', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51fcefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render\n",
    "(\n",
    "    null_stats_frame\n",
    "    .style\n",
    "    .hide(axis='index')\n",
    "    .bar(color='#FFA07A', subset=['Null %'], vmax=100)\n",
    "    .format({'Null %': '{:.03f}'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b9000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of missing values percentages for each column\n",
    "(\n",
    "    null_percentage_frame\n",
    "    .sort_values('Null %', ascending=False)\n",
    "    .plot\n",
    "    .bar(x='Column Name', **MATPLOTLIB_BAR_PLOT_ARGS)\n",
    "    .set_ylabel('Missing Values [%]')\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097449c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate large random dataframe\n",
    "shape=(100000, 8)\n",
    "na_prob = 0.1\n",
    "zeros = np.zeros(shape)\n",
    "zeros[np.random.uniform(size=shape) < na_prob] = None\n",
    "df = pd.DataFrame(zeros, columns=(range(shape[1])))\n",
    "\n",
    "def missing_values_matrix(df, fig_size=(15, 10), cmap=sns.color_palette(['#FFFFFF', '#FFA07A']), transpose=False):\n",
    "    # Compute missing values matrix\n",
    "    missing_values = df.isna()\n",
    "    if transpose:\n",
    "        missing_values = missing_values.transpose()\n",
    "\n",
    "    # Plot missing values matrix\n",
    "    ax = sns.heatmap(missing_values, cbar=False, cmap=cmap)\n",
    "\n",
    "    # Add vertical/horizontal lines separating columns\n",
    "    line_args = {'color': cmap[0], 'linewidth': 1}\n",
    "    if transpose:\n",
    "        ax.hlines(range(len(df.columns)), *ax.get_xlim(), **line_args)\n",
    "    else:\n",
    "        ax.vlines(range(len(df.columns)), *ax.get_ylim(), **line_args)\n",
    "\n",
    "    # Set axes\n",
    "    ticks = [0, df.shape[0]]\n",
    "    if transpose:\n",
    "        ax.set_xticks(ticks)\n",
    "        ax.set_xticklabels(ticks)\n",
    "    else:\n",
    "        ax.set_yticks(ticks)\n",
    "        ax.set_yticklabels(ticks)\n",
    "    ax.figure.set_size_inches(*fig_size)\n",
    "    ax.set_title('Missing values matrix')\n",
    "    labels = ['Row number', 'Column Name']\n",
    "    ax.set_xlabel(labels[1 - transpose])\n",
    "    ax.set_ylabel(labels[transpose])\n",
    "\n",
    "    # Display frame around the plot\n",
    "    for _, spine in ax.spines.items():\n",
    "        spine.set_visible(True)\n",
    "    plt.show()\n",
    "\n",
    "missing_values_matrix(df, transpose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38805308",
   "metadata": {},
   "source": [
    "### Constant Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSTANT = 0\n",
    "\n",
    "if isinstance(COLUMN_SUBSET, str):\n",
    "    COLUMN_SUBSET = [COLUMN_SUBSET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e40e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count constant counts\n",
    "constant_count = (dataset[COLUMN_SUBSET] == CONSTANT).sum()\n",
    "constant_percentage = 100 * constant_count / len(dataset)\n",
    "\n",
    "# Convert series to frames\n",
    "constant_count_frame = series_to_frame(\n",
    "    series=constant_count,\n",
    "    index_name='Column Name',\n",
    "    column_name=f'\"{CONSTANT}\" Count')\n",
    "\n",
    "constant_percentage_frame = series_to_frame(\n",
    "    series=constant_percentage,\n",
    "    index_name='Column Name',\n",
    "    column_name=f'\"{CONSTANT}\" %'\n",
    ")\n",
    "# Merge absolute and relative counts\n",
    "constant_stats_frame = (\n",
    "    constant_count_frame\n",
    "    .merge(constant_percentage_frame, on='Column Name')\n",
    "    .sort_values(f'\"{CONSTANT}\" %', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cb5cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render\n",
    "(\n",
    "    constant_stats_frame\n",
    "    .style\n",
    "    .hide(axis='index')\n",
    "    .bar(color='#FFA07A', subset=[f'\"{CONSTANT}\" %'], vmax=100)\n",
    "    .format({f'\"{CONSTANT}\" %': '{:.03f}'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcca470",
   "metadata": {},
   "source": [
    "## Number of rows with at least one value missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_SUBSET = DEFAULT_COLUMN_SUBSET\n",
    "\n",
    "if isinstance(COLUMN_SUBSET, str):\n",
    "    COLUMN_SUBSET = [COLUMN_SUBSET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087d4b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_missing_value = (\n",
    "    dataset[COLUMN_SUBSET]\n",
    "    .isna()\n",
    "    .any(axis=1)\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "percentage_rows_missing_value = 100 * num_rows_missing_value / len(dataset)\n",
    "\n",
    "missing_value_rows_info = {\n",
    "    'Missing value column subset' : str(list(COLUMN_SUBSET)),\n",
    "    'Missing value row count': f'{num_rows_missing_value:,}',\n",
    "    'Missing value row percentage': f'{percentage_rows_missing_value:.02f} %'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439444f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render\n",
    "render_dictionary(missing_value_rows_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e54904b",
   "metadata": {},
   "source": [
    "## Number of duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_SUBSET = DEFAULT_COLUMN_SUBSET\n",
    "\n",
    "if isinstance(COLUMN_SUBSET, str):\n",
    "    COLUMN_SUBSET = [COLUMN_SUBSET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ec71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_duplicated_rows = (\n",
    "    dataset\n",
    "    .duplicated(subset=COLUMN_SUBSET)\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "percentage_duplicated_rows = 100 * num_duplicated_rows / len(dataset)\n",
    "\n",
    "duplicate_rows_info = {\n",
    "    'Duplicate rows column subset' : str(list(COLUMN_SUBSET)),\n",
    "    'Duplicate row count': f'{num_duplicated_rows:,}',\n",
    "    'Duplicate row percentage': f'{percentage_duplicated_rows:.02f} %'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96835a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render\n",
    "render_dictionary(duplicate_rows_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7396b57d",
   "metadata": {},
   "source": [
    "# Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331555a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_SUBSET = DEFAULT_COLUMN_SUBSET\n",
    "\n",
    "if isinstance(COLUMN_SUBSET, str):\n",
    "    COLUMN_SUBSET = [COLUMN_SUBSET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f543e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To add or delete statistics to or from certain features use:\n",
    "    descriptive_stats_funcs['ColumnName']['NewStatistic'] = new_statistic_func\n",
    "    del descriptive_stats_funcs['ColumnName']['UnwantedStatistic']\n",
    "\"\"\"\n",
    "\n",
    "# Choose which statistics will be calculated for which columns\n",
    "descriptive_stats_funcs = {}\n",
    "quantile_stats_funcs = {}\n",
    "for col_name in COLUMN_SUBSET:\n",
    "    descriptive_stats_funcs[col_name] = copy.deepcopy(DEFAULT_DESCRIPTIVE_STATISTICS)\n",
    "    quantile_stats_funcs[col_name] = copy.deepcopy(DEFAULT_QUANTILE_STATISTICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7928e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To change the way a column gets handled in the univariate analysis, change the properties\n",
    "in the col_props dictionary for example by setting the is_categorical flag\n",
    "col_props['ColumnName']['is_categorical'] = False\n",
    "\"\"\"\n",
    "\n",
    "# Set properties of each column/feature that impacts the way it gets analyzed\n",
    "col_props = {}\n",
    "for col_name in COLUMN_SUBSET:\n",
    "    is_categorical = utils.is_categorical(dataset[col_name])\n",
    "    col_props[col_name] = {'is_categorical': is_categorical}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f655a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The loop below iterates through each feature and outputs univariate analysis of that feature.\n",
    "\n",
    "To add your own analysis either expand the loop with your own code and/or add HTML strings to\n",
    "the html_table list (for example via html_table.append([df1.to_html(), df2.to_html()])). This\n",
    "way of rendering HTML allows for example two dataframes to be rendered side by side. The html_table\n",
    "list's elements (also lists) represent rows and elements within\n",
    "those elements represent cells.\n",
    "\"\"\"\n",
    "\n",
    "# Iterate through columns and output univariate analysis results\n",
    "for col_name in col_props.keys():\n",
    "    # Print column name and basic info\n",
    "    display(Markdown('---'))\n",
    "    display(Markdown(f'## {col_name}'))\n",
    "    display(Markdown('Categorical' if col_props[col_name]['is_categorical'] else 'Numerical'))\n",
    "\n",
    "    html_table = []\n",
    "\n",
    "    # Calculate statistics depending on variable type\n",
    "    if col_props[col_name]['is_categorical']:\n",
    "        common_values = utils.top_frequent_values(dataset[col_name], n_top=5)\n",
    "        common_values_html = dict_to_html(common_values)\n",
    "        common_values_html = add_html_heading(common_values_html, 'Most frequent values', 2)\n",
    "        html_table.append([common_values_html])\n",
    "    else:\n",
    "        # Calculate statistics using chosen for the current feature\n",
    "        desc_stats = {}\n",
    "        quant_stats = {}\n",
    "        for stat_name, stat_func in descriptive_stats_funcs[col_name].items():\n",
    "            desc_stats[stat_name] = format_number(stat_func(dataset[col_name]), thousand_separator=' ')\n",
    "        for stat_name, stat_func in quantile_stats_funcs[col_name].items():\n",
    "            quant_stats[stat_name] = format_number(stat_func(dataset[col_name]), thousand_separator=' ')\n",
    "        # Render statistics tables side by side\n",
    "        desc_stats_html = add_html_heading(dict_to_html(desc_stats), 'Descriptive Statistics')\n",
    "        quant_stats_html = add_html_heading(dict_to_html(quant_stats), 'Quantile Statistics')\n",
    "        # Add tables to HTML table for rendering\n",
    "        html_table.append([desc_stats_html, quant_stats_html])\n",
    "\n",
    "    # Render statistics in an HTML table\n",
    "    display(HTML(subcells_html(html_table)))\n",
    "\n",
    "    # Plot column distribution\n",
    "    # Don't plot if there are a lot of unique values in categorical column\n",
    "    if col_props[col_name]['is_categorical'] and dataset[col_name].nunique() > 50:\n",
    "        warnings.warn(f'Column \"{col_name}\" is categorical but has a lot of unique values, skipping distribution plotting')\n",
    "    else:\n",
    "        if col_props[col_name]['is_categorical']:\n",
    "            fig = plt.figure(figsize=(20, 7))\n",
    "            ax = dataset[col_name].value_counts().plot.bar(figure=fig)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.show()\n",
    "        else:\n",
    "            fig, (ax_box, ax_hist) = plt.subplots(\n",
    "                nrows=2,\n",
    "                sharex=True,\n",
    "                gridspec_kw={'height_ratios': (.15, .85)},\n",
    "                figsize=(20, 7)\n",
    "            )\n",
    "            sns.boxplot(dataset[col_name].dropna(), ax=ax_box)\n",
    "            sns.distplot(dataset[col_name].dropna(), kde=False, ax=ax_hist)\n",
    "            ax_box.set(xlabel='')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644754d",
   "metadata": {},
   "source": [
    "# Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ad9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_BIVARIATE = [c for c in COLUMN_SUBSET if not utils.is_categorical(dataset[c])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Default dictionary of bivariate statistics that will be calculated for numerical columns\n",
    "    Dicionary signature: 'CorrelationName': corr_func\n",
    "    corr_func signature: stat_func(series: pandas.DataFrame) -> pandas.DataFrame\n",
    "\"\"\"\n",
    "\n",
    "DEFAULT_CORRELATIONS = {\n",
    "    'pearson' : utils.pearson,\n",
    "    'spearman': utils.spearman,\n",
    "    'kendall' : utils.kendall,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5050225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation(df, corr_name, fig_size=(10, 7), font_size=15, color_map=\"Blues\"):\n",
    "    # show header\n",
    "    display(Markdown(f'## {corr_name.capitalize()} Correlation'))\n",
    "\n",
    "    # calculate correlation between columns\n",
    "    corr = DEFAULT_CORRELATIONS[corr_name](df)\n",
    "\n",
    "    # plot correlation heatmap\n",
    "    ax = sns.heatmap(corr.values, cmap=color_map)\n",
    "\n",
    "    # set axes\n",
    "    ax.set_xticks(range(len(COLUMNS_BIVARIATE)))\n",
    "    ax.set_xticklabels(COLUMNS_BIVARIATE, fontsize=font_size, rotation=90)\n",
    "    ax.set_yticklabels(COLUMNS_BIVARIATE, fontsize=font_size, rotation=0)\n",
    "\n",
    "    # set size\n",
    "    ax.figure.set_size_inches(*fig_size)\n",
    "    plt.show()\n",
    "\n",
    "for corr_name in DEFAULT_CORRELATIONS:\n",
    "    plot_correlation(dataset[COLUMNS_BIVARIATE], corr_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e770c5",
   "metadata": {},
   "source": [
    "## Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c59c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.pair_plot(dataset[COLUMNS_BIVARIATE])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc861fad",
   "metadata": {},
   "source": [
    "## Contingency Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b989a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contingency_table(\n",
    "    df, columns1, columns2, include_total=True, hide_zeros=True, scaling_func=np.cbrt, colormap='Blues', size_factor=0.7, fontsize=15\n",
    "):\n",
    "    if isinstance(columns1, str):\n",
    "        columns1 = [columns1]\n",
    "    if isinstance(columns2, str):\n",
    "        columns2 = [columns2]\n",
    "    table = pd.crosstab([df[col] for col in columns1], [df[col] for col in columns2], margins_name='Total', margins=include_total)\n",
    "    annot = table.replace(0, '') if hide_zeros else table\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        scaling_func(table),\n",
    "        annot=annot,\n",
    "        fmt='',\n",
    "        cbar=False,\n",
    "        cmap=colormap,\n",
    "        linewidths=0.1,\n",
    "        xticklabels=1,\n",
    "        yticklabels=1,\n",
    "        annot_kws = {'fontsize': fontsize}\n",
    "    )\n",
    "    ax.figure.set_size_inches(\n",
    "        size_factor * len(table.columns),\n",
    "        size_factor * len(table)\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=fontsize)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=fontsize)\n",
    "\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize=fontsize)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=fontsize)\n",
    "\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=fontsize)\n",
    "    ax.xaxis.set_label_position('top')\n",
    "\n",
    "    # Viusally separate the margins\n",
    "    if include_total:\n",
    "        ax.vlines(len(table.columns) - 1, ymin=0, ymax=len(table), color='grey')\n",
    "        ax.hlines(len(table) - 1, xmin=0, xmax=len(table.columns), color='grey')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "contingency_table(dataset, 'Sex', 'Pclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb172628",
   "metadata": {},
   "source": [
    "# Group analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb8851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import colorlover as cl\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize, to_hex\n",
    "\n",
    "from edvart.data_types import DataType, infer_data_type\n",
    "from edvart.pandas_formatting import format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742cb9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_GROUP_DESCRIPTIVE_STATISTICS = {\n",
    "    '# Unique values': utils.num_unique_values,\n",
    "    'Sum': utils.sum_,\n",
    "    'Mode': utils.mode,\n",
    "    'Mean': utils.mean,\n",
    "    'Std': utils.std,\n",
    "    'Mean abs dev': utils.mad,\n",
    "    'Median abs dev': utils.median_absolute_deviation,\n",
    "    'Relative Std': utils.coefficient_of_variation,\n",
    "    'Kurtosis': utils.kurtosis,\n",
    "    'Skewness': utils.skewness\n",
    "}\n",
    "\n",
    "DEFAULT_GROUP_QUANTILE_STATISTICS = {\n",
    "    'Min': utils.minimum,\n",
    "    'Q1': utils.quartile1,\n",
    "    'Median': utils.median,\n",
    "    'Q3': utils.quartile3,\n",
    "    'Max': utils.maximum,\n",
    "    'Range': utils.value_range,\n",
    "    'IQR': utils.iqr,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_barplot(\n",
    "    df,\n",
    "    groupby,\n",
    "    column,\n",
    "    group_count_threshold=20,\n",
    "    conditional_probability=True,\n",
    "    xaxis_tickangle=0,\n",
    "    alpha=0.5\n",
    "):\n",
    "    num_cat = df[column].nunique()\n",
    "    if num_cat > group_count_threshold:\n",
    "        warnings.warn(f'Too many categories ({num_cat}), not plotting distribution')\n",
    "        return\n",
    "\n",
    "    pivot = (\n",
    "        df\n",
    "        .pivot_table(\n",
    "            index=groupby,\n",
    "            columns=column,\n",
    "            aggfunc='size',\n",
    "            fill_value=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if conditional_probability:\n",
    "        pivot = pivot.divide(pivot.sum(axis=1), axis=0)\n",
    "        pivot.fillna(value=0)\n",
    "\n",
    "    # Choose color palette\n",
    "    colors = cl.scales['9']['qual']['Set1']\n",
    "    color_idx = 0\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for idx, row in pivot.iterrows():\n",
    "        if hasattr(idx, '__len__') and not isinstance(idx, str):\n",
    "            group_name = '_'.join([str(i) for i in idx])\n",
    "        else:\n",
    "            group_name = idx\n",
    "        color = colors[color_idx % len(colors)]\n",
    "        color_idx += 1\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=pivot.columns,\n",
    "                y=row,\n",
    "                name=group_name,\n",
    "                opacity=alpha,\n",
    "                marker_color=color\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if conditional_probability:\n",
    "        yaxis_title = f'P({column} | {groupby})'\n",
    "    else:\n",
    "        yaxis_title = f'Freq({column} | {groupby})'\n",
    "\n",
    "    fig.update_layout(\n",
    "        barmode='group',\n",
    "        xaxis_tickangle=xaxis_tickangle,\n",
    "        xaxis_title=column,\n",
    "        yaxis_title=yaxis_title\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def overlayed_histograms(\n",
    "    df,\n",
    "    groupby,\n",
    "    column,\n",
    "    bins=None,\n",
    "    density=True,\n",
    "    alpha=0.5\n",
    "):\n",
    "    # Modified Freedman-Diaconis bin number inference if bins is None\n",
    "    if bins is None:\n",
    "        IQR = df[column].quantile(0.75) - df[column].quantile(0.25)\n",
    "        bin_width = 1 / np.cbrt(len(df)) * IQR\n",
    "    else:\n",
    "        bin_width = (df[column].max() - df[column].min()) / bins\n",
    "    bin_config = {\n",
    "        'start': df[column].min(),\n",
    "        'end': df[column].max(),\n",
    "        'size': bin_width\n",
    "    }\n",
    "\n",
    "    # Choose color palette\n",
    "    colors = cl.scales['9']['qual']['Set1']\n",
    "    color_idx = 0\n",
    "\n",
    "    # Distribution plot\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        row_heights=[0.3, 0.7],\n",
    "        vertical_spacing=0.02\n",
    "    )\n",
    "    for name, group in df.groupby(groupby):\n",
    "        if hasattr(name, '__len__') and not isinstance(name, str):\n",
    "            group_name = '_'.join([str(i) for i in name])\n",
    "        else:\n",
    "            group_name = name\n",
    "        color = colors[color_idx % len(colors)]\n",
    "        color_idx += 1\n",
    "        # Add to boxplot\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                x=group[column],\n",
    "                name=group_name,\n",
    "                legendgroup=group_name,\n",
    "                showlegend=False,\n",
    "                marker_color=color\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1\n",
    "        )\n",
    "        # Add to histogram\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=group[column],\n",
    "                name=group_name,\n",
    "                legendgroup=group_name,\n",
    "                xbins=bin_config,\n",
    "                histnorm='density' if density else '',\n",
    "                marker_color=color,\n",
    "                opacity=alpha\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1\n",
    "        )\n",
    "    fig.update_layout(barmode='overlay')\n",
    "    fig.update_xaxes(title_text=column, row=2, col=1)\n",
    "    yaxis_title = 'Density' if density else 'Frequency'\n",
    "    fig.update_yaxes(title_text=yaxis_title, row=2, col=1)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def group_missing_matrix(\n",
    "    df,\n",
    "    groupby,\n",
    "    round_decimals=2,\n",
    "    heatmap=True,\n",
    "    foreground_colormap='bone',\n",
    "    background_colormap='OrRd',\n",
    "    sort=True,\n",
    "    sort_by=None,\n",
    "    ascending=False\n",
    "):\n",
    "    gb = df.groupby(groupby)\n",
    "\n",
    "    # Calculate number of samples in each group\n",
    "    sizes = gb.size().rename('Group Size')\n",
    "\n",
    "    # Calculate missing values percentage of each column for each group\n",
    "    missing = gb.apply(lambda g: g.isna().sum(axis=0))\n",
    "    missing = missing.divide(sizes, axis=0) * 100\n",
    "    missing.fillna(value=0, inplace=True)\n",
    "    missing = missing.round(decimals=round_decimals)\n",
    "\n",
    "    if missing.sum().sum() == 0:\n",
    "        print('There are no missing values')\n",
    "        return\n",
    "\n",
    "    # Concatenate group sizes and missing value percentages\n",
    "    final_table = pd.concat([sizes, missing], axis=1)\n",
    "\n",
    "    # Sort columns to better identify groups with missing data\n",
    "    all_columns = [col for col in missing.columns if col != groupby and col not in groupby]\n",
    "    if sort:\n",
    "        if sort_by is None:\n",
    "            sort_by = all_columns\n",
    "        final_table.sort_values(\n",
    "            by=sort_by,\n",
    "            axis=0,\n",
    "            ascending=ascending,\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "    # Drop columns with no missing data\n",
    "    non_missing = final_table.sum(axis=0) == 0\n",
    "    final_table = final_table.loc[:, ~non_missing]\n",
    "\n",
    "    colored_columns = [col for col in final_table if col in all_columns]\n",
    "\n",
    "    # Apply conditional formatting to each cell except group size column\n",
    "    if heatmap:\n",
    "        fg_cmap = cm.get_cmap(foreground_colormap)\n",
    "        bg_cmap = cm.get_cmap(background_colormap)\n",
    "        norm = Normalize(vmin=0, vmax=100)\n",
    "        def color_cell(value):\n",
    "            fg_hex = to_hex(fg_cmap(norm(value)))\n",
    "            bg_hex = to_hex(bg_cmap(norm(value)))\n",
    "            return f\"\"\"\n",
    "                color: {fg_hex};\n",
    "                background-color: {bg_hex};\n",
    "            \"\"\"\n",
    "        render = (\n",
    "            final_table\n",
    "            .style\n",
    "            .applymap(\n",
    "                func=color_cell,\n",
    "                subset=pd.IndexSlice[:, colored_columns]\n",
    "            )\n",
    "            .format(\n",
    "                formatter='{0:.2f} %',\n",
    "                subset=pd.IndexSlice[:, colored_columns]\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        render = (\n",
    "            final_table\n",
    "            .style\n",
    "            .format(\n",
    "                formatter='{0:.2f} %',\n",
    "                subset=pd.IndexSlice[:, colored_columns]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Render table\n",
    "    display(render)\n",
    "\n",
    "\n",
    "def within_group_stats(df, groupby, column, stats, round_decimals=2):\n",
    "    gb = df.groupby(groupby)[column]\n",
    "    group_stats = []\n",
    "    for name, func in stats.items():\n",
    "        group_stats.append(\n",
    "            gb\n",
    "            .apply(func)\n",
    "            .rename(name)\n",
    "        )\n",
    "    stats_table = pd.concat(group_stats, axis=1)\n",
    "    stats_table = stats_table.round(decimals=round_decimals)\n",
    "    display(stats_table)\n",
    "\n",
    "\n",
    "def group_analysis(\n",
    "    df,\n",
    "    groupby,\n",
    "    within_group_statistics=True,\n",
    "    conditioned_missing_values=True,\n",
    "    distribution_plots=True\n",
    "):\n",
    "    if conditioned_missing_values:\n",
    "        display(Markdown('## Missing values for each group'))\n",
    "        group_missing_matrix(df, groupby)\n",
    "\n",
    "    if distribution_plots or within_group_statistics:\n",
    "        for col in df.columns:\n",
    "            if col != groupby and col not in groupby:\n",
    "                display(Markdown(f'---'))\n",
    "                display(Markdown(f'### *{col}*'))\n",
    "                datatype = infer_data_type(df[col])\n",
    "                if datatype == DataType.NUMERIC:\n",
    "                    if within_group_statistics:\n",
    "                        within_group_stats(dataset, groupby, col, DEFAULT_GROUP_DESCRIPTIVE_STATISTICS)\n",
    "                        within_group_stats(dataset, groupby, col, DEFAULT_GROUP_QUANTILE_STATISTICS)\n",
    "                    overlayed_histograms(df, groupby, col)\n",
    "                else:\n",
    "                    group_barplot(df, groupby, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b82d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_analysis(df=dataset, groupby=['Sex', 'Pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c60830a",
   "metadata": {},
   "source": [
    "# Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98707da",
   "metadata": {},
   "source": [
    "## Principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_PCA = [c for c in COLUMN_SUBSET if not utils.is_categorical(dataset[c])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cebcfe",
   "metadata": {},
   "source": [
    "## First vs Second principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_first_vs_second(df, standardize=True, figsize=(10,7)):\n",
    "    pca = PCA(n_components=2)\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        data_scaled = scaler.fit_transform(df[COLUMNS_PCA].dropna())\n",
    "        pca_components = pca.fit_transform(data_scaled)\n",
    "    else:\n",
    "        pca_components = pca.fit_transform(df[COLUMNS_PCA].dropna())\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.scatter(pca_components[:, 0], pca_components[:, 1], figure=fig)\n",
    "    plt.xlabel('First principal component')\n",
    "    plt.ylabel('Second principal component')\n",
    "    plt.show()\n",
    "    print(f'Explained variance ratio: {pca.explained_variance_ratio_[:2].sum() * 100 :.2f}%')\n",
    "\n",
    "pca_first_vs_second(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ca1d8",
   "metadata": {},
   "source": [
    "## Explained variance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f05c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_explained_variance(df, standardize=True, figsize=(10,7), show_grid=True):\n",
    "    pca = PCA()\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        data_scaled = scaler.fit_transform(df[COLUMNS_PCA].dropna())\n",
    "        pca.fit(data_scaled)\n",
    "    else:\n",
    "        pca.fit(df[COLUMNS_MULTIVARIATE])\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.plot(pca.explained_variance_ratio_, figure=fig)\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_), figure=fig)\n",
    "\n",
    "    plt.legend(['Individual component', 'Cumulative'])\n",
    "    plt.xlabel('Principal component #')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xticks(\n",
    "        ticks=range(len(pca.explained_variance_ratio_)),\n",
    "        labels=range(1, (len(pca.explained_variance_ratio_) + 1))\n",
    "    )\n",
    "    if show_grid:\n",
    "        plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "pca_explained_variance(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bcee36",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umap(\n",
    "    df,\n",
    "    columns=None,\n",
    "    color_col=None,\n",
    "    interactive=True,\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    metric='euclidean',\n",
    "    random_state=42,\n",
    "    figsize=(15, 15),\n",
    "    opacity=0.8,\n",
    "    show_message=True\n",
    "):\n",
    "    if columns is None:\n",
    "        columns = [col for col in df.columns if is_numeric(df[col])]\n",
    "    else:\n",
    "        for col in columns:\n",
    "            if not is_numeric(df[col]):\n",
    "                raise ValueError(f'UMAP cannot be computed for non-numeric column {col}')\n",
    "    embedder = umap.UMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        metric=metric,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    df = df.dropna()\n",
    "    embedded = embedder.fit_transform(df[columns])\n",
    "\n",
    "    # Multiplier which makes plotly interactive plots (size in pixels) and\n",
    "    # matplotlib plots (size in inches) about the same size\n",
    "    INCHES_TO_PIXELS = 64\n",
    "    if interactive:\n",
    "        layout=dict(\n",
    "            width=figsize[0] * INCHES_TO_PIXELS,\n",
    "            height=figsize[1] * INCHES_TO_PIXELS,\n",
    "            xaxis=dict(showgrid=False, showticklabels=False),\n",
    "            yaxis=dict(showgrid=False, showticklabels=False),\n",
    "            legend=dict(title=f'<b>{color_col}</b>')\n",
    "        )\n",
    "\n",
    "    if color_col is not None:\n",
    "        is_color_categorical = not is_numeric(df[color_col]) or utils.is_categorical(df[color_col])\n",
    "        if interactive:\n",
    "            fig = go.Figure(\n",
    "                layout=layout\n",
    "            )\n",
    "            if is_color_categorical:\n",
    "                df = df.copy()\n",
    "                x_name, y_name = '__edvart_umap_x', '__edvart_umap_y'\n",
    "                df[x_name] = embedded[:, 0]\n",
    "                df[y_name] = embedded[:, 1]\n",
    "                for group_name, group in df.groupby(color_col):\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=group[x_name],\n",
    "                            y=group[y_name],\n",
    "                            mode='markers',\n",
    "                            marker=dict(opacity=opacity),\n",
    "                            name=group_name,\n",
    "                            text=[\n",
    "                                '</br>'.join(f'{col_name}: {df.loc[row, col_name]}'\n",
    "                                             for col_name\n",
    "                                             in group.columns.drop([x_name, y_name])\n",
    "                                )\n",
    "                                for row\n",
    "                                in group.index\n",
    "                            ],\n",
    "                        )\n",
    "                    )\n",
    "            else:\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=embedded[:, 0],\n",
    "                        y=embedded[:, 1],\n",
    "                        mode='markers',\n",
    "                        marker=dict(\n",
    "                            color=df[color_col],\n",
    "                            opacity=opacity,\n",
    "                            colorbar=dict(title=color_col)\n",
    "                        ),\n",
    "                        text=['</br>'.join(f'{col_name}: {df.loc[row, col_name]}' for col_name in df.columns) for row in df.index],\n",
    "                    ),\n",
    "                )\n",
    "            fig.show()\n",
    "        else:\n",
    "            if is_color_categorical:\n",
    "                color_categorical = pd.Categorical(df[color_col])\n",
    "                color_codes = color_categorical.codes\n",
    "            else:\n",
    "                color_codes = df[color_col]\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=figsize)\n",
    "            scatter = ax.scatter(embedded[:, 0], embedded[:, 1], c=color_codes, alpha=opacity)\n",
    "            if is_color_categorical:\n",
    "                legend_elements = scatter.legend_elements()\n",
    "                ax.legend(legend_elements[0], color_categorical.categories, title=color_col)\n",
    "            else:\n",
    "                cbar = plt.colorbar(scatter)\n",
    "                cbar.ax.set_ylabel(color_col)\n",
    "            # Remove ticks - the exact locations of embedded points are irrelevant\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            plt.show()\n",
    "    else:\n",
    "        if interactive:\n",
    "            fig = go.Figure(\n",
    "                go.Scatter(\n",
    "                        x=embedded[:, 0],\n",
    "                        y=embedded[:, 1],\n",
    "                        mode='markers',\n",
    "                        marker=dict(opacity=opacity),\n",
    "                        text=['</br>'.join(f'{col_name}: {df.loc[row, col_name]}' for col_name in df.columns) for row in df.index],\n",
    "                ),\n",
    "                layout=layout\n",
    "            )\n",
    "            fig.show()\n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize=figsize)\n",
    "            ax.scatter(embedded[:, 0], embedded[:, 1], alpha=opacity)\n",
    "            # Remove ticks - the exact locations of embedded points are irrelevant\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            plt.show()\n",
    "\n",
    "    if show_message:\n",
    "        print('UMAP requires proper setting of hyperparameters. ')\n",
    "        print('If results are unsatisfactory, consider trying different values of parameters `n_neighbors`, `min_dist` and `metric`.')\n",
    "\n",
    "plot_umap(dataset, interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e4b81f",
   "metadata": {},
   "source": [
    "## Parallel coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_colorscale(n, saturation=0.5, lightness=0.5):\n",
    "    \"\"\"Generate a colorscale of n discrete colors\n",
    "    equally spaced around the HSL wheel\n",
    "    with constant saturation and lightness\n",
    "    \"\"\"\n",
    "    for i in range(n):\n",
    "        color = f'hsl({(i / n) * 360 :.2f}, {saturation * 100 :.2f}%, {lightness * 100 :.2f}%)'\n",
    "        yield (i / n, color)\n",
    "        yield ((i + 1) / n, color)\n",
    "\n",
    "def parallel_coordinates(df, columns=None, drop_na=False, hide_columns=None, color_col=None, show_colorscale=True):\n",
    "    if columns is None:\n",
    "        columns = list(df.columns)\n",
    "    if hide_columns is not None:\n",
    "        columns = list(filter(lambda x: x not in hide_columns, columns))\n",
    "    df = df.copy()\n",
    "    if drop_na:\n",
    "        df = df.dropna()\n",
    "    if color_col is not None:\n",
    "        categorical_color = not is_numeric(df[color_col])\n",
    "\n",
    "        if categorical_color:\n",
    "            categories = df[color_col].unique()\n",
    "            colorscale = list(discrete_colorscale(len(categories)))\n",
    "            # encode categories into numbers\n",
    "            color_series = pd.Series(pd.Categorical(df[color_col]).codes)\n",
    "        else:\n",
    "            color_series = df[color_col]\n",
    "            colorscale = 'Bluered_r'\n",
    "\n",
    "        line = {\n",
    "            'color': color_series,\n",
    "            'colorscale': colorscale,\n",
    "            'showscale': show_colorscale,\n",
    "            'colorbar': { 'title': color_col, 'lenmode': 'pixels', 'len': 300 }\n",
    "        }\n",
    "\n",
    "        if categorical_color:\n",
    "            line['colorbar'].update({\n",
    "                'tickvals': color_series.unique(),\n",
    "                'ticktext': categories,\n",
    "                'lenmode': 'pixels',\n",
    "                'len': min(40 * len(categories), 300)\n",
    "            })\n",
    "    else:\n",
    "        line = None\n",
    "\n",
    "    numeric_columns = [c for c in columns if is_numeric(df[c])]\n",
    "    categorical_columns = [c for c in columns if not is_numeric(df[c])]\n",
    "    # Add numeric columns to dimensions\n",
    "    dimensions = [\n",
    "        {\n",
    "            'label': col_name,\n",
    "            'values': dataset[col_name],\n",
    "        }\n",
    "        for col_name in numeric_columns\n",
    "    ]\n",
    "    # Add categorical columns to dimensions\n",
    "    for col_name in categorical_columns:\n",
    "        categories = df[col_name].unique()\n",
    "        values = pd.Series(pd.Categorical(df[col_name]).codes)\n",
    "        dimensions.append({\n",
    "            'label': col_name,\n",
    "            'values': values,\n",
    "            'tickvals': values.unique(),\n",
    "            'ticktext': categories\n",
    "        })\n",
    "\n",
    "    fig = go.Figure(\n",
    "        go.Parcoords(\n",
    "            line = line,\n",
    "            dimensions = dimensions\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "parallel_coordinates(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626a1c96",
   "metadata": {},
   "source": [
    "# Parallel categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dfbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_categories(df, columns=None, hide_columns=None, color_col=None):\n",
    "    if columns is None:\n",
    "        columns = [col for col in df.columns if utils.is_categorical(df[col])]\n",
    "    if hide_columns is not None:\n",
    "        columns = [col for col in columns if col not in hide_columns]\n",
    "    if color_col is not None:\n",
    "        categorical_color = not is_numeric(df[color_col])\n",
    "\n",
    "        if categorical_color:\n",
    "            categories = df[color_col].unique()\n",
    "            colorscale = list(discrete_colorscale(len(categories)))\n",
    "            # encode categories into numbers\n",
    "            color_series = pd.Series(pd.Categorical(df[color_col]).codes)\n",
    "        else:\n",
    "            color_series = df[color_col]\n",
    "            colorscale = 'Bluered_r'\n",
    "\n",
    "        line = {\n",
    "            'color': color_series,\n",
    "            'colorscale': colorscale,\n",
    "            'colorbar': {'title': color_col}\n",
    "        }\n",
    "\n",
    "        if categorical_color:\n",
    "            line['colorbar'].update({\n",
    "                'tickvals': color_series.unique(),\n",
    "                'ticktext': categories,\n",
    "                'lenmode': 'pixels',\n",
    "                'len': min(40 * len(categories), 300)\n",
    "            })\n",
    "    dimensions = [\n",
    "        go.parcats.Dimension(values=df[col_name], label=col_name)\n",
    "        for col_name in columns\n",
    "    ]\n",
    "\n",
    "    fig = go.Figure(\n",
    "        go.Parcats(\n",
    "            dimensions=dimensions,\n",
    "            line=line\n",
    "        )\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "parallel_categories(dataset, color_col='Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a708ccee",
   "metadata": {},
   "source": [
    "# Time series analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb28c84",
   "metadata": {},
   "source": [
    "## Boxplots over time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf2f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load time series example dataset\n",
    "dataset_ts = edvart.example_datasets.dataset_pollution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de224e",
   "metadata": {},
   "source": [
    "## Time analysis plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_analysis_plot(df, columns=None, separate_plots=False, color_col=None):\n",
    "    if color_col is not None:\n",
    "        _time_analysis_colored_plot(df, columns=columns, color_col=color_col)\n",
    "        return\n",
    "    if columns is None:\n",
    "        columns = [col for col in df.columns if is_numeric(df[col])]\n",
    "    else:\n",
    "        for col in columns:\n",
    "            if not is_numeric(df[col]):\n",
    "                raise ValueError(f'Cannot plot timeanalysis plot for non-numeric column {col}')\n",
    "\n",
    "    data = [\n",
    "        go.Scatter(\n",
    "            x=df.index,\n",
    "            y=df[col],\n",
    "            name=col,\n",
    "            mode='lines'\n",
    "        )\n",
    "        for col in columns\n",
    "    ]\n",
    "\n",
    "    layout = dict(\n",
    "        xaxis_rangeslider_visible=True\n",
    "    )\n",
    "    if separate_plots:\n",
    "        for trace in data:\n",
    "            display(Markdown(f'---\\n### {trace.name}'))\n",
    "            go.Figure(data=trace, layout=layout).show()\n",
    "    else:\n",
    "        go.Figure(data=data, layout=layout).show()\n",
    "\n",
    "def _time_analysis_colored_plot(df, columns=None, color_col=None):\n",
    "    if columns is None:\n",
    "        columns = [col for col in df.columns if is_numeric(df[col])]\n",
    "    else:\n",
    "        for col in columns:\n",
    "            if not is_numeric(df[col]):\n",
    "                raise ValueError(f'Cannot plot timeanalysis plot for non-numeric column {col}')\n",
    "    layout = dict(\n",
    "        xaxis_rangeslider_visible=True\n",
    "    )\n",
    "    if not utils.is_categorical(df[color_col]):\n",
    "        raise ValueError(f'Cannot color by non-categorical column `{color_col}`')\n",
    "    if df[color_col].nunique() > 20:\n",
    "        warnings.warn('Coloring by categorical column with many unique values!')\n",
    "    df_color_shifted = df[color_col].shift(-1)\n",
    "    for col in columns:\n",
    "        data = [\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                # GroupBy would normally be preferred, but we want a connected line\n",
    "                # Therefore, we also plot a connecting line\n",
    "                # to the next point where category changes\n",
    "                y=df[col].mask((df[color_col] != category) & (df_color_shifted != category)),\n",
    "                name = str(category),\n",
    "                mode='lines',\n",
    "                connectgaps=False\n",
    "            )\n",
    "            for category in df[color_col].unique()\n",
    "        ]\n",
    "        display(Markdown(f'---\\n### {col}'))\n",
    "        fig = go.Figure(data=data, layout=layout).show()\n",
    "\n",
    "time_analysis_plot(dataset_ts[:5000], color_col='wnd_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56009cb",
   "metadata": {},
   "source": [
    "## Rolling statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_statistics(\n",
    "    df, columns=None,\n",
    "    show_bands=True, band_width=1., show_std_dev=True, window_size=20,\n",
    "    color_std='#CD5C5C', color_mean='#2040FF', color_band='#90E0FF'\n",
    "):\n",
    "    if columns is None:\n",
    "        columns = [col for col in df.columns if is_numeric(df[col])]\n",
    "    else:\n",
    "        for col in columns:\n",
    "            if not is_numeric(df[col]):\n",
    "                raise ValueError(f'Cannot plot rolling statistics for non-numeric column `{col}`')\n",
    "\n",
    "    df_rolling = df[columns].rolling(window_size)\n",
    "    df_rolling_mean = df_rolling.mean()[window_size - 1:]\n",
    "    df_rolling_std = df_rolling.std()[window_size - 1:]\n",
    "    index = df.index[window_size - 1:]\n",
    "    layout = dict(\n",
    "        xaxis_rangeslider_visible=True\n",
    "    )\n",
    "    data = []\n",
    "    for col in columns:\n",
    "        data.append([])\n",
    "        if show_std_dev:\n",
    "            trace_std = go.Scatter(\n",
    "                x=index,\n",
    "                y=df_rolling_std[col],\n",
    "                mode='lines',\n",
    "                name='Rolling std. dev.',\n",
    "                line={'color': color_std}\n",
    "            )\n",
    "            data[-1].append(trace_std)\n",
    "\n",
    "        trace_mean = go.Scatter(\n",
    "            x=index,\n",
    "            y=df_rolling_mean[col],\n",
    "            mode='lines',\n",
    "            name='Rolling mean',\n",
    "            line={'color': color_mean }\n",
    "        )\n",
    "        data[-1].append(trace_mean)\n",
    "\n",
    "        if show_bands:\n",
    "            # Plot upper band\n",
    "            trace_mean_plus_std = go.Scatter(\n",
    "                x=index,\n",
    "                y=df_rolling_mean[col] + band_width * df_rolling_std[col],\n",
    "                mode='lines',\n",
    "                name='Rolling mean + {} rolling std. dev.'.format('' if band_width == 1 else str(band_width) + ' * '),\n",
    "                line={'color': color_band}\n",
    "            )\n",
    "            # Plot lower band\n",
    "            trace_mean_minus_std = go.Scatter(\n",
    "                x=index,\n",
    "                y=df_rolling_mean[col] - band_width * df_rolling_std[col],\n",
    "                mode='lines',\n",
    "                name='Rolling mean - {} rolling std. dev.'.format('' if band_width == 1 else str(band_width) + ' * '),\n",
    "                line={'color': color_band}\n",
    "            )\n",
    "            data[-1].extend([trace_mean_plus_std, trace_mean_minus_std])\n",
    "\n",
    "    for col_name, col_data in zip(columns, data):\n",
    "        display(Markdown(f'---\\n### {col_name}'))\n",
    "        go.Figure(data=col_data, layout=layout).show()\n",
    "\n",
    "rolling_statistics(dataset_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed3b41",
   "metadata": {},
   "source": [
    "## Boxplots over time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a575200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_grouping_functions():\n",
    "    return {\n",
    "        'Hour': lambda x: f'{x.day}/{x.month}/{x.year} {x.hour}:00',\n",
    "        'Day': lambda x: f'{x.day}/{x.month}/{x.year}',\n",
    "        'Week': lambda x: f'W{x.week}, {x.year if x.dayofweek < x.dayofyear else x.year - 1}',\n",
    "        'Month': lambda x: f'{x.month_name()[:3]} {x.year}',\n",
    "        'Quarter': lambda x: f'Q{x.quarter} {x.year}',\n",
    "        'Year': lambda x: f'{x.year}',\n",
    "        'Decade': lambda x: f'{x.year // 10 * 10}s'\n",
    "    }\n",
    "\n",
    "def get_default_grouping_func(df, max_nvalues=80):\n",
    "    # find most granular grouping which does not produce too many values\n",
    "    for name, func in default_grouping_functions().items():\n",
    "        if df.index.to_series().apply(func).nunique() < max_nvalues:\n",
    "            return name, func\n",
    "    else:\n",
    "        # If no grouping is rough enough, use the roughest available\n",
    "        return name, func\n",
    "\n",
    "def boxplots_over_time(df, columns=None, grouping_function = None, grouping_name = None, figsize=(20, 7), color=None):\n",
    "    default_grouping_funcs = default_grouping_functions()\n",
    "    if grouping_name in default_grouping_funcs:\n",
    "        grouping_func = default_grouping_funcs[grouping_name]\n",
    "    elif grouping_function is None:\n",
    "        grouping_name, grouping_function = get_default_grouping_func(df)\n",
    "\n",
    "    if columns is None:\n",
    "        columns = [col for col in df.columns if is_numeric(df[col])]\n",
    "    for col in columns:\n",
    "            if not is_numeric(df[col]):\n",
    "                raise ValueError(\n",
    "                    f'Cannot plot rolling statistics for non-numeric column `{col}`'\n",
    "                )\n",
    "\n",
    "    for column in columns:\n",
    "        if not is_numeric(df[column]):\n",
    "            raise ValueError(f'Cannot plot boxplot for non-numeric column {column}')\n",
    "        display(Markdown('---'))\n",
    "        display(Markdown(f'## {column}'))\n",
    "        ax = sns.boxplot(\n",
    "            x=df.index.to_series().apply(grouping_function),\n",
    "            y=df[column],\n",
    "            color=color\n",
    "        )\n",
    "\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "        if grouping_name is not None:\n",
    "            ax.set_xlabel(grouping_name)\n",
    "        ax.figure.set_size_inches(*figsize)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "boxplots_over_time(dataset_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bf2166",
   "metadata": {},
   "source": [
    "## Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b1104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_decomposition(df, columns=None, figsize=(20, 10), period=None):\n",
    "    df = df.interpolate(method='time')\n",
    "    if pd.infer_freq(df.index) is None and period is None:\n",
    "        warnings.warn(f'Period could not be inferred, please set the period parameter to a suitable value. Decomposition will not be plotted.')\n",
    "        return\n",
    "    if columns is None:\n",
    "        columns = [col for col in df.columns if is_numeric(df[col])]\n",
    "    else:\n",
    "        for col in columns:\n",
    "            if not is_numeric(df[col]):\n",
    "                raise ValueError(f'Only numeric columns are supported, column {col} does not appear to be numeric.')\n",
    "    for col in columns:\n",
    "        display(Markdown(f'---\\n### {col}'))\n",
    "        decomposition = sm.tsa.seasonal_decompose(df[col], period=period)\n",
    "        fig = decomposition.plot()\n",
    "        fig.set_size_inches(*figsize)\n",
    "        fig.axes[0].set_title(None)\n",
    "        fig.axes[0].set_ylabel('Original')\n",
    "        fig.axes[-1].set_ylabel('Residual')\n",
    "        plt.show()\n",
    "\n",
    "timeseries_decomposition(dataset_ts, period=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e2a0d",
   "metadata": {},
   "source": [
    "## Stationarity tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8cee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_stationarity_tests():\n",
    "    return {\n",
    "        'KPSS Test (constant)': partial(sm.tsa.stattools.kpss, regression='c', nlags='auto'),\n",
    "        'KPSS Test (trend)': partial(sm.tsa.stattools.kpss, regression='ct', nlags='auto'),\n",
    "        'Augmented Dickey-Fuller Test': sm.tsa.stattools.adfuller\n",
    "    }\n",
    "\n",
    "def stationarity_tests(df, columns=None, kpss_const=True, kpss_trend=True, adfuller=True):\n",
    "    df = df.copy().dropna()\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    stat_tests = default_stationarity_tests()\n",
    "    if not kpss_const:\n",
    "        stat_tests.pop('KPSS Test (constant)', None)\n",
    "    if not kpss_trend:\n",
    "        stat_tests.pop('KPSS Test (trend)', None)\n",
    "    if not adfuller:\n",
    "        stat_tests.pop('Augmented Dickey-Fuller Test', None)\n",
    "\n",
    "    columns = [col for col in columns if is_numeric(df[col])]\n",
    "    for col in columns:\n",
    "        test_values_df = pd.DataFrame()\n",
    "        display(Markdown(f'---\\n### {col}'))\n",
    "        for name, func in stat_tests.items():\n",
    "            with warnings.catch_warnings(record=True) as w:\n",
    "                test_vals = func(df[col])\n",
    "            stat, pvalue = test_vals[:2]\n",
    "            value_dict = {\n",
    "                'Test statistic': format_number(stat, thousand_separator=' '),\n",
    "                'P-value': ('<' if len(w) >= 1 else '') + format_number(pvalue, thousand_separator= ' '),\n",
    "            }\n",
    "            value_series = pd.Series(value_dict)\n",
    "            test_values_df[name] = value_series\n",
    "        display(test_values_df.style)\n",
    "\n",
    "stationarity_tests(dataset_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8423e531",
   "metadata": {},
   "source": [
    "## Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e9f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acf(df, columns=None, lags=None, figsize=(15, 5), partial=False):\n",
    "    if columns is None:\n",
    "        columns = [col for col in df.columns if is_numeric(df[col])]\n",
    "    else:\n",
    "        for col in columns:\n",
    "            if not is_numeric(df[col]):\n",
    "                raise ValueError(f'Cannot plot autocorrelation for non-numeric column `{col}`')\n",
    "\n",
    "    plot_func = tsaplots.plot_pacf if partial else tsaplots.plot_acf\n",
    "    for col in columns:\n",
    "        display(Markdown(f'---\\n### {col}'))\n",
    "        fig = plot_func(df[col].dropna(), lags=lags)\n",
    "        ax = fig.axes[0]\n",
    "        ax.set_title('')\n",
    "        ax.set_xlabel('Lag')\n",
    "        ax.set_ylabel(('Partial ' if partial else '') + 'Autocorrelation')\n",
    "        fig.set_size_inches(*figsize)\n",
    "        plt.show()\n",
    "\n",
    "plot_acf(dataset_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd616d8",
   "metadata": {},
   "source": [
    "## Partial autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b682e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf = partial(plot_acf, partial=True)\n",
    "\n",
    "plot_pacf(dataset_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac3ec8f",
   "metadata": {},
   "source": [
    "## Fourier transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca9982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft(df, sampling_rate, columns=None, figsize=(15, 6), log=False, freq_min=None, freq_max=None):\n",
    "    if columns is None:\n",
    "        columns = [col for col in df.columns if is_numeric(df[col])]\n",
    "    else:\n",
    "        for col in columns:\n",
    "            if not is_numeric(df[col]):\n",
    "                raise ValueError(f'Cannot perform Fourier transform for non-numeric column `{col}`')\n",
    "    index_freq = pd.infer_freq(df.index) or ''\n",
    "    for col in columns:\n",
    "        # FFT requires samples at regular intervals\n",
    "        df_col = df[col].interpolate(method='time')\n",
    "        df_col_centered = df_col - df_col.mean()\n",
    "        fft_result = np.fft.fft(df_col_centered)\n",
    "\n",
    "        amplitude = np.abs(fft_result) * 2 / len(df)\n",
    "        fft_freq = np.fft.fftfreq(len(amplitude), 1. / sampling_rate)\n",
    "        idx_pos_freq = fft_freq > 0\n",
    "        fft_freq, amplitude = fft_freq[idx_pos_freq], amplitude[idx_pos_freq]\n",
    "\n",
    "        y = 10 * np.log10(amplitude) if log else amplitude\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax.stem(fft_freq, y, use_line_collection=True, markerfmt='')\n",
    "        ax.set_xlabel(f'Frequency [1 / {sampling_rate}{index_freq}]')\n",
    "        ax.set_ylabel('Amplitude' + (' [dB]' if log else ''))\n",
    "        ax.set_xlim(freq_min, freq_max)\n",
    "        display(Markdown(f'---\\n### {col}'))\n",
    "        plt.show()\n",
    "\n",
    "# Hourly data with sampling rate 24 -> 24 daily samples\n",
    "fft(dataset_ts, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d95580",
   "metadata": {},
   "source": [
    "## Short-time Fourier transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a444324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft(\n",
    "    df, sampling_rate, window_size, overlap=None, log=True,\n",
    "    columns=None, window='hann', scaling='spectrum', figsize=(20, 7),\n",
    "    freq_min=None, freq_max=None\n",
    "):\n",
    "    if columns is None:\n",
    "        columns = [col for col in df.columns if is_numeric(df[col])]\n",
    "    else:\n",
    "        for col in columns:\n",
    "            if not is_numeric(df[col]):\n",
    "                raise ValueError(f'Cannot perform STFT for non-numeric column {col}')\n",
    "    index_freq = pd.infer_freq(df.index) or ''\n",
    "    for col in columns:\n",
    "        display(Markdown(f'---\\n### {col}'))\n",
    "        freqs, times, Sx = signal.spectrogram(\n",
    "            # interpolate to get samples at regular time intervals\n",
    "            df[col].interpolate(method='time'),\n",
    "            fs=sampling_rate,\n",
    "            window=window,\n",
    "            nperseg=window_size,\n",
    "            # Overlap defaults to window_size // 8\n",
    "            noverlap=overlap,\n",
    "            scaling=scaling\n",
    "        )\n",
    "\n",
    "        # Add small positive value to avoid 0 in log\n",
    "        y = 10 * np.log10(Sx + 1e-12) if log else Sx\n",
    "\n",
    "        f, ax = plt.subplots(figsize=figsize)\n",
    "        ax.pcolormesh(times, freqs, y, cmap='viridis')\n",
    "\n",
    "        ax.set_ylabel(f'Frequency [1/({sampling_rate}{index_freq})]')\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylim(freq_min, freq_max)\n",
    "        # Show times from index in xticks\n",
    "        ax.set_xticklabels(\n",
    "            df.index[\n",
    "                list(map(lambda time: int(time * sampling_rate), ax.get_xticks()[:-1]))\n",
    "            ]\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "# Hourly data -> 24 samples/day with weekly windows\n",
    "stft(dataset_ts, 24, 168)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "cell_metadata_json": true,
   "notebook_metadata_filter": "kernelspec,jupytext"
  },
  "kernelspec": {
   "display_name": "edvart-wpUo52om-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
